---
title: "Situación problema: Ghostbusters"
author:
  - name: "Jessica Dong"
  - name: "Ebony Valadez"
  - name: "Emiliano Guzmán"
  - name: "Rafael Gutiérrez "
date: today
lang: es
abstract: |
 Este proyecto implementa un clasificador Naïve Bayes para categorizar relatos de fenómenos paranormales recopilados de la plataforma Your Ghost Stories en internte. Se construyó una base de datos aplicando web scraping que incluye título, lugar, categoría y descripción de cada historia. Se llevó a cabo un procesamiento de los textos mediante un análisis del lenguaje natural y fueron representados en una matriz basada en la frecuencia de las palabras. Con estos datos se entrenaron y evaluaron clasificadores Naïve Bayes en diferentes escenarios, realizando ajustes de Laplace smoothing, distribución Poisson y validación cruzada. Se pretende que con los resultados sea posible simplificar la clasificación dentro del análisis de textos de manera automatizada, así como plantearlo con diversos enfoques de distintas área.
keywords: ["web scrapping", "clasificador Naïve Bayes","Natural Language Processing", "modelado probabilístico"]

execute:
  echo: false       
  warning: false
  message: false

crossref:
  fig-prefix: "Figura"
  tbl-prefix: "Tabla"
  eq-prefix: "Ecuación"

format:
  html:
    toc: true
    toc-depth: 3
    number-sections: true
    theme: cosmo
    code-fold: show
    code-tools: true
    df-print: paged
    math: mathjax
  pdf:
    documentclass: article
    toc: true
    toc-depth: 3
    number-sections: true
    geometry: "margin=1in"
    fig-cap-location: bottom
    tbl-cap-location: top
---

# Introducción

Para lograr un análisis automatizado de texto, es necesario incorporar técnicas de procesamiento de lenguaje natural (NLP), entendido como un campo que “se ocupa de cómo las computadoras entienden, procesan y manipulan los lenguajes humanos, utilizando métodos estadísticos, aprendizaje automático, redes neuronales y minería de texto” (Network of the National Library of Medicine, 2022). En este proyecto, dichas técnicas son aplicadas con el objetivo de clasificar relatos de fenómenos paranormales que fueron obtenidos mediante web scraping del portal Your Ghost Stories e incorporados a una base de datos.

Con los textos recolectados se realizó una matriz basada en las frecuencias de las palabras para así llevar a cabo múltiples entrenamientos de modelos probabilísticos usando el clasificador Naïve Bayes que es de suma utilidad en tareas de minería de texto, así como también se implementaron variantes ajustadas con Laplace smoothing, distribución Poisson y validación cruzada. El objetivo principal del proyecto es predecir la categoría de cada relato con los datos y la base de datos planteada y así analizar cómo diferentes configuraciones del modelo de clasificación afectan el desempeño en escenarios multiclase y binarios y la manera en la que categoriza.

# Metodología

## 1. Recolección de datos

La información se obtuvo mediante **web scraping** del portal *Your Ghost Stories*, que concentra relatos de experiencias paranormales reportadas por usuarios en distintos contextos geográficos. Antes de la extracción se verificó el cumplimiento de las políticas del sitio utilizando el paquete `robotstxt` de R, comprobando que las rutas de interés estuvieran habilitadas para el acceso automatizado.

La extracción se realizó con `rvest` y `httr`, identificando los elementos HTML que contienen el **título** y la **descripción** de cada historia. Para ampliar la cobertura, se implementó una función iterativa que recorrió múltiples páginas (con control de paginación) y combinó dimensiones nativas del sitio: **categorías temáticas** (p. ej., avistamientos, posesiones, figuras sombrías) y **ubicaciones** (p. ej., estados de EE. UU.). Se incluyó un retardo entre solicitudes (`delay`) y un encabezado de agente de usuario para un acceso respetuoso al servidor. El resultado de cada iteración se consolidó en un archivo `.csv`.

## 2. Estructura del conjunto de datos

El conjunto de datos final se estructuró con las siguientes variables mínimas:

-   `titulo`: encabezado del relato.
-   `descripcion`: texto principal del relato.
-   `categoria`: tipo de evento paranormal según taxonomía del sitio.
-   `lugar`: ubicación asociada al relato (cuando estuvo disponible).

El dataset se almacenó en formato **CSV**, lo que facilita su posterior lectura y procesamiento reproducible en R.

## 3. Procesamiento y limpieza de texto

Para preparar el corpus, se utilizaron `tidytext`, `stringr`, `dplyr` y `tidyr`:

1.  **Tokenización**: transformación de la columna `descripcion` a unidades léxicas (palabras).
2.  **Depuración**: eliminación de *stopwords* (en inglés) y filtrado de tokens no informativos (p. ej., secuencias numéricas).
3.  **Normalización básica**: conversión a minúsculas y saneamiento ligero de caracteres, manteniendo la semántica original.

Este preprocesamiento generó un corpus “limpio” apto para el análisis exploratorio y semántico.

## 4. Análisis exploratorio de texto

Se calcularon **frecuencias de palabras** a nivel global y por `categoria`, con el objetivo de identificar léxico recurrente y patrones narrativos. Las principales distribuciones se visualizaron mediante gráficos de barras (palabras más frecuentes en el total y top-k por categoría), lo que permitió contrastar temáticas y vocabulario dominante entre tipos de fenómenos.

#### Palabras más frecuentes en los relatos 

![Figura 1. Palabras más frecuentes en relatos](palabras_frecuentes.png){fig-align="center"}

La gráfica presenta las 20 palabras más frecuentes en los relatos paranormales analizados. Se observa que términos como *house*, *story* y *time* destacan como los más repetidos, lo que sugiere que muchos relatos están ambientados en el hogar y giran en torno a experiencias personales narradas en forma de historia.

#### Top palabras por categoría

![**Figura 2.** Top 10 palabras más frecuentes por categoría.\
Cada panel muestra las 10 palabras más repetidas en los relatos correspondientes a cada categoría temática.](top_palabras_por_categoria.png){fig-align="center"}

La figura muestra las 10 palabras más frecuentes en cada categoría de relatos paranormales. Se observa que, aunque algunos términos como *house*, *story* y *night* aparecen de manera recurrente en distintas categorías, cada temática también presenta vocablos característicos. Esto refleja cómo las experiencias narradas se diferencian según el tipo de fenómeno, pero mantienen un vocabulario común asociado a escenarios, tiempos y personajes frecuentes en este tipo de relatos.

## 5. Análisis de sentimientos

Para caracterizar la **carga emocional** del corpus se integraron tres lexicones:

-   **NRC**: asigna emociones básicas (p. ej., miedo, tristeza, alegría, sorpresa).
-   **Bing**: clasifica polaridad (positiva/negativa).
-   **AFINN**: asigna puntajes enteros de intensidad (negativa a positiva).

La unión léxica (join por `word`) permitió: - Estimar la **distribución de emociones** por `categoria` (NRC). - Cuantificar la **polaridad** (Bing) y la **intensidad** global por relato (AFINN), obteniendo para este último una suma de puntajes por `titulo`.\
Los resultados se representaron con gráficos de barras y un histograma de puntajes AFINN para explorar la dispersión afectiva entre historias.

#### Emociones más frecuentes 

![**Figura 3.** Emociones más frecuentes en relatos paranormales.\
Cada panel muestra las cinco emociones más mencionadas dentro de cada categoría de relatos, destacando la prevalencia de sentimientos negativos como miedo y tristeza, junto con otros como sorpresa o anticipación.](figuras/sentimientos_por_categoria.png){width="100%" fig-align="center"}

La figura muestra las emociones más frecuentes en los relatos paranormales, clasificadas por categoría. Se observa que, aunque cada tipo de relato presenta matices distintos, las emociones predominantes tienden a repetirse entre categorías, reflejando sentimientos de miedo, sorpresa y tristeza. Estos resultados sugieren que las narrativas paranormales, independientemente de la temática, despiertan un conjunto común de respuestas emocionales en los narradores.

#### Distribución AFINN

![**Figura 4.** Distribución de puntajes AFINN en relatos paranormales.\
La mayoría de los relatos presentan un puntaje cercano a cero, lo que refleja una tendencia hacia la neutralidad, aunque también aparecen relatos con cargas emocionales más negativas o positivas.](figuras/distribucion_afinn.png){width="70%" fig-align="center"}

La figura muestra la distribución de los puntajes AFINN calculados a partir de los relatos paranormales. La mayoría de los valores se concentran alrededor de 0, lo que indica que los relatos tienden a tener una carga emocional relativamente neutra en conjunto. Sin embargo, también se observa una dispersión hacia valores negativos y positivos, lo que refleja la coexistencia de narrativas con emociones tanto desfavorables (miedo, tristeza) como favorables (esperanza, alivio).

## 6. Matriz dispersa 

### Construcción de la matriz documento-término

Para poder aplicar técnicas de minería de texto y modelado probabilístico, fue necesario transformar los relatos recopilados en una representación numérica adecuada. Con este propósito se construyó una **matriz documento-término (DTM)**, en la cual cada fila corresponde a un relato y cada columna representa una palabra única del vocabulario obtenido tras el preprocesamiento.

El procedimiento seguido fue, primero que nada descomponer las descripciones en tokens `unnest_tokens()` para después eliminar palabras reduntantes, signos de puntuación, números y palabras con escasa frecuencia utilizando la librería `tidytext`. Posteriormente, se calculó la frecuencia absoluta de cada palabra dentro de cada relato. Este proceso corresponde a un **count vectorizer**, donde se transforma el texto en vectores numéricos que representan la ocurrencia de cada término.

Para la matriz dispersa (sparse matrix), se organizaron los resultados de las frecuencias, debido a la gran cantidad de términos posibles frente al reducido número de palabras presentes en cada relato. En esta estructura, la mayoría de las celdas permanecen en cero, lo que optimiza el almacenamiento y la eficiencia computacional. Finalmente, a cada fila de la matriz se le asoció la categoría correspondiente al tipo de evento paranormal, de modo que la matriz no solo represente las características textuales, sino también la etiqueta de clase necesaria para entrenar los clasificadores.

Además de eliminar stopwords y palabras poco informativas, se realizó un filtrado léxico sencillo al descartar aquellos términos que aparecían en menos de cinco relatos, con el objetivo de reducir el ruido y el tamaño del vocabulario. Si bien se experimentó de manera exploratoria con criterios más estrictos de filtrado por frecuencia relativa (proporción de documentos) y con la transformación TF-IDF, finalmente el modelo se ajustó únicamente usando la matriz de conteo simple, ya que ni los filtros adicionales ni la ponderación TF-IDF ofrecieron mejoras relevantes en el desempeño sobre este conjunto de datos. A pesar de estos intentos, se observó que el clasificador Naïve Bayes no era capaz de distinguir de manera efectiva entre todas las categorías presentes en el conjunto original: la matriz de confusión resultante mostraba que, al incluir todas las clases, el modelo tendía a predecir únicamente unas pocas, dejando el resto prácticamente sin aciertos, independientemente del filtrado realizado. Por esta razón, la opción de reducir la tarea a 3-5 clases principales solo se implementó como experimento exploratorio, pero en el análisis principal se mantuvo el enfoque multiclase.

## 7. Limitaciones

-   La extracción depende de la **estructura HTML** del sitio; cambios en el marcado podrían requerir ajustes en los selectores.
-   La calidad de `lugar` y `categoria` está condicionada a la forma de publicación y a la **disponibilidad** de metadatos.
-   Los métodos léxicos de sentimientos (NRC, Bing, AFINN) no capturan **ironía, negación compleja** ni **dependencias contextuales**; por tanto, los resultados deben interpretarse como aproximaciones exploratorias.

# Aplicación y resultados de diferentes modelos

## 1. Entrenamiento de clasificador naïve Bayes

Para la primera aproximación se dividió la base en 70% entrenamiento y 30% prueba. Se entrenó un **Naïve Bayes Multinomial** (Laplace = 1) sobre la matriz documento–término (`dtm_filt`) y las etiquetas (`labels_filt`). La matriz resultó altamente dispersa (~99.9% de ceros), con dimensiones:  

- Entrenamiento: 156,632 documentos × 15,815 términos  
- Prueba: 67,128 documentos × 15,815 términos  

La matriz de confusión (omitida por extensión) mostró que la mayoría de las predicciones se concentraron en unas pocas clases frecuentes, dejando a la mayoría de las categorías sin representación adecuada.

**Métricas globales (multiclase, macro):**

| Métrica              | Valor  |
|----------------------|:------:|
| Exactitud (Accuracy) | 0.0498 |
| Precisión macro      | 0.0491 |
| Recall macro         | 0.0503 |
| F1 macro             | 0.0848 |

El desempeño del modelo fue bajo, con una capacidad limitada para distinguir entre más de veinte categorías temáticas. Esto sugiere que, aunque el Naïve Bayes multinomial es eficiente en textos, la gran cantidad de clases y la dispersión del vocabulario afectan su desempeño.

---

## 2. Ajuste de clasificador

En un segundo intento se entrenó un **Naïve Bayes clásico** (Laplace = 1) pero utilizando únicamente las 500 palabras más frecuentes del conjunto de entrenamiento. Esta reducción de dimensionalidad buscó simplificar el modelo y eliminar ruido.

La nueva matriz de confusión confirmó el mismo patrón de concentración en unas pocas clases, aunque con menor complejidad computacional.

Solo tres columnas de predicción tienen conteos distintos de cero:  
- **A Haunted Life**
- **Psychic / Medium**
- **Shadow People**.  

Todas las demás columnas de clase predicha son 0 en todas las filas.

| Reference (clase real)                              | Pred: A Haunted Life | Pred: Psychic / Medium | Pred: Shadow People |
|-----------------------------------------------------|---------------------:|-----------------------:|-------------------:|
| A Haunted Life                                      | 824                  | 668                    | 2060               |
| Apparitions / Voices / Touches                      | 824                  | 668                    | 2060               |
| Children Who See Spirits                            | 824                  | 668                    | 2060               |
| Demons / Possessions / Exorcisms                    | 824                  | 668                    | 2060               |
| Family / Friends Visits                             | 824                  | 668                    | 2060               |
| Ghost Hunting                                       | 824                  | 668                    | 2060               |
| Ghost Tours & Haunted Hotels                        | 824                  | 668                    | 2060               |
| Haunted Items                                       | 824                  | 668                    | 2060               |
| Haunted Places                                      | 824                  | 668                    | 2060               |
| Misc                                                | 824                  | 668                    | 2060               |
| Non Human Entities                                  | 738                  | 615                    | 1923               |
| Old Hags / Night Attacks / Sleep Paralysis          | 713                  | 582                    | 1853               |
| Orbs / Lights / Mists                               | 713                  | 582                    | 1853               |
| Ouija Board / Seances                               | 713                  | 582                    | 1853               |
| Pets / Animals                                      | 713                  | 582                    | 1853               |
| Photographs / Videos / EVP                          | 713                  | 582                    | 1853               |
| Poltergeists / Physical Manifestations              | 713                  | 582                    | 1853               |
| Psychic / Medium                                    | 713                  | 582                    | 1853               |
| Shadow People                                       | 713                  | 582                    | 1853               |
| Succubus / Incubus / Sexual Ghosts                  | 713                  | 582                    | 1853               |

Fuera de estas tres columnas de predicción, **todas las demás clases predichas presentan 0** en cada fila de la matriz.

Esto confirma que, aunque la reducción de dimensionalidad disminuyó la complejidad, el modelo no logra discriminar entre la mayoría de las clases y concentra prácticamente todas las predicciones en tres categorías dominantes.

## 3. Dicotimización en eventos de las variables
Con el objetivo de simplificar el problema de multiclase, se optó por dicotomizar los eventos en las variables (empleando la función **case_when**)y ahora se categorización consiste únicamente de pertenecer al grupo "Haunted places" o no pertenecer (siendo la opción "Other"). 

Se reentrenaron ambos clasificadores (multinomial y naive_bayes()) en el **escenario binario** y los resultados fueron similares, aunque con ligeras variaciones en el número de aciertos en la clase minoritaria (“Haunted Places”). lo cual muestra que la simplificación binaria facilita el aprendizaje, pero no resuelve el problema de desbalance. A partir de este planteamiento se obtuvo un accuracy de más del 94%; sin embargo, se llegó a una precision de apenas 0.05 y un recall de 0.0051 para la clase minoritaria.

| Métrica              | Valor  |
|----------------------|:------:|
| Exactitud (Accuracy) | 0.9423 |
| Precisión macro      | 0.0500 |
| Recall macro         | 0.0051 |
| F1 macro             | 0.0092 |

## 4. Implementación de la distribución Poisson
Resultando en una técnica más adecuada para conteos, se aplicó modelo que considera una distribución de Poisson (empleando **usepoisson = TRUE**), del cual se obtuvo un desempeño similar al modelo binario aplicado anteriormente, pero con una mejor en la detección de relatos pertenecientes a "Haunted places", aumentando los aciertos de 18 a 27 y mostrando cómo la distribución adaptada a Poisson mejoró el ajuste.

La matriz de confusión obtenida de este modelo es la siguiente:

| Reference       | Haunted Places | Other  |
|-----------------|:--------------:|:------:|
| Haunted Places  |      25        |  3527  |
| Other           |      447       | 63129  |

Lo cual muestra cómo el modelo predice en la mayoría de los casos la clase "Other"; no obstante, tiende a ignorar "Haunted Places", mostrando cómo **el clasificador se sesga a una clase** debido al desbalance esntre éstas. Si lo que se pretende es detectar "Haunted places", el modelo no es de mucha utilidad.


## 5. Técnica Laplace smoothing

Laplace smoothing es una técnica que se emplea para **ajustar las probabilidades** en modelos como Naïve Bayes y así evitar que una probabilidad se vuelva cero, tal como en este caso cuando una palabra no aparece en el conjunto que se utilizó para entrenar. Esta técnica tiene como objetivo garantizar que todo término tenga una probabilidad mínima, haciendo de esta forma al modelo más robusto frente a eventos no comunes o no observados.

Se evaluó el efecto del parámetro de suavizamiento de Laplace probando valores de α = 0.5, 1, 2 y 3, así como también se realizó la validación cruzada con 5 folds e indicó que el mejor desempeño se alcanzó con α = 0.5, obteniendo una accuracy promedio cercana al 94%. De igual forma, se observó cómo **valores más altos redujeron la precisión del modelo**. 

Evaluación inicial:

| Valor de α (Laplace) | Accuracy  |
|----------------------|:---------:|
| 0.5                  | 0.9471    |
| 1.0                  | 0.9423    |
| 2.0                  | 0.9342    |
| 3.0                  | 0.9298    |

Evaluación luego del cross validation:

| Valor de α (Laplace) | Accuracy  |
|----------------------|:---------:|
| 0.5                  | 0.9376    |
| 1.0                  | 0.9320    |
| 2.0                  | 0.9295    |
| 3.0                  | 0.9306    |


Estos resultados confirman que la selección de un parámetro de suavizamiento adecuado es fundamental para mejorar el accuracy del clasificador y que el modelo resulte útil para categorizar los eventos.


# Conclusiones

# Referencias

*He replied / she cried: Text mining and gender roles.* En STA 199. <https://sta199-f22-1.github.io/ae/ae-21-jane-austen-A.html>

National Network of Libraries of Medicine. (2022). *Natural language processing (NLP)*. NNLM Data Glossary. https://www.nnlm.gov/guides/data-glossary/natural-language-processing

Matrix R Package Development Team. (s.f.). *sparseMatrix: General Sparse Matrix Construction from Nonzero Entries*. CRAN R Project. <https://cran.r-project.org/web/packages/Matrix/Matrix.pdf>

Jayaswal, V. (2020, noviembre 22). Laplace smoothing in Naive Bayes algorithm. Towards Data Science. https://towardsdatascience.com/laplace-smoothing-in-naive-bayes-algorithm-9c237a8bdece
